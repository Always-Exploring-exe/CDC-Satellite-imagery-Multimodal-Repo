{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ac07728",
   "metadata": {},
   "source": [
    "# Make Final Test Predictions\n",
    "\n",
    "This notebook generates final predictions on the test set by loading the trained fusion model and combining it with XGBoost baseline predictions. It applies the same preprocessing pipeline, loads satellite images, and produces the final submission file `final_submission.csv` with predicted house prices.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8e3261c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 1. Loading and Merging Data ---\n",
      "Inference Features (23): ['bedrooms', 'bathrooms', 'sqft_living', 'sqft_lot', 'floors', 'waterfront', 'view', 'condition', 'grade', 'sqft_above', 'sqft_basement', 'zipcode', 'lat', 'long', 'sqft_living15', 'sqft_lot15', 'year_sold', 'month_sold', 'day_sold', 'house_age', 'was_renovated', 'years_since_update', 'xgb_pred_log']\n",
      "Features in Test: 23 (Should correspond to model input)\n",
      "--- 2. Loading Model ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abhi\\AppData\\Local\\Temp\\ipykernel_37948\\990202277.py:180: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 3. Running Inference ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Predicting: 100%|██████████| 43/43 [01:58<00:00,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 4. Fusing Scores & Saving ---\n",
      "Success! Predictions saved to: final_submission.csv\n",
      "Sample:\n",
      "           id  predicted_price\n",
      "0  2591820310     3.766912e+05\n",
      "1  7974200820     8.695827e+05\n",
      "2  7701450110     1.134790e+06\n",
      "3  9522300010     2.001476e+06\n",
      "4  9510861140     7.223207e+05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import models, transforms \n",
    "import rasterio\n",
    "from tqdm import tqdm\n",
    "\n",
    "# --- CONFIG ---\n",
    "TEST_TABULAR_PATH = 'test_tabular.csv'\n",
    "XGB_TEST_PATH = 'xg_boost_test.csv' \n",
    "IMG_DIR = 'naip_images/test_640' # Double check if this should be 'test_640' or 'train_640' based on your folder structure\n",
    "MODEL_PATH = 'sota_fusion_best.pth'\n",
    "OUTPUT_PATH = 'final_submission.csv'\n",
    "\n",
    "BATCH_SIZE = 128\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ==========================================\n",
    "# 1. PREPROCESSING (FIXED: Drops raw cols)\n",
    "# ==========================================\n",
    "def preprocess_tabular_features(df):\n",
    "    df = df.copy()\n",
    "    \n",
    "    # 1. Date Handling\n",
    "    if 'date' in df.columns:\n",
    "        df['date'] = pd.to_datetime(df['date'])\n",
    "        df['year_sold'] = df['date'].dt.year\n",
    "        df['month_sold'] = df['date'].dt.month\n",
    "        df['day_sold'] = df['date'].dt.day\n",
    "    \n",
    "    # 2. Feature Engineering\n",
    "    ref_year = 2025\n",
    "    if 'yr_built' in df.columns:\n",
    "        df['house_age'] = ref_year - df['yr_built']\n",
    "        \n",
    "    if 'yr_renovated' in df.columns:\n",
    "        df['was_renovated'] = (df['yr_renovated'] > 0).astype(int)\n",
    "        last_update = df['yr_renovated'].where(df['yr_renovated'] != 0, df['yr_built'])\n",
    "        df['years_since_update'] = ref_year - last_update\n",
    "\n",
    "    # --- FIX: DROP RAW COLUMNS TO MATCH TRAINING DIMENSIONS ---\n",
    "    cols_to_drop = ['yr_built', 'yr_renovated']\n",
    "    df = df.drop(columns=cols_to_drop, errors='ignore')\n",
    "\n",
    "    return df\n",
    "\n",
    "# ==========================================\n",
    "# 2. DATASET DEFINITION\n",
    "# ==========================================\n",
    "class TestMultimodalDataset(Dataset):\n",
    "    def __init__(self, tabular_df, img_dir):\n",
    "        self.df = tabular_df\n",
    "        self.img_dir = img_dir\n",
    "        \n",
    "        # --- FEATURE SELECTION ---\n",
    "        excluded_cols = [\n",
    "            'id', 'date', 'price', 'log_price', 'price_pred_xgb', 'xg_boost_price',\n",
    "            'residual', 'residual_log', 'target_residual', 'abs_residual',\n",
    "            'error_category', 'alpha', 'log_price_pred', 'log_xgb'\n",
    "        ]\n",
    "        \n",
    "        # 1. Prepare Features\n",
    "        # Ensure XGB Log Prediction is included as a feature\n",
    "        if 'xg_boost_price' in self.df.columns:\n",
    "            self.df['xgb_pred_log'] = np.log(self.df['xg_boost_price'])\n",
    "        \n",
    "        # Select numeric features\n",
    "        self.features = [c for c in self.df.columns if c not in excluded_cols]\n",
    "        if 'xgb_pred_log' not in self.features and 'xgb_pred_log' in self.df.columns:\n",
    "            self.features.append('xgb_pred_log')\n",
    "            \n",
    "        print(f\"Inference Features ({len(self.features)}): {self.features}\")\n",
    "\n",
    "        # 2. Standardize Tabular Data\n",
    "        self.tab_data = self.df[self.features].values.astype(np.float32)\n",
    "        self.tab_mean = self.tab_data.mean(axis=0)\n",
    "        self.tab_std = self.tab_data.std(axis=0) + 1e-6\n",
    "        self.tab_data = (self.tab_data - self.tab_mean) / self.tab_std\n",
    "        \n",
    "        self.ids = self.df['id'].values\n",
    "        \n",
    "        # 3. Image Normalization\n",
    "        self.normalize = transforms.Normalize(\n",
    "            mean=[0.485, 0.456, 0.406, 0.485], \n",
    "            std=[0.229, 0.224, 0.225, 0.229]\n",
    "        )\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_id = self.ids[idx]\n",
    "        img_path = os.path.join(self.img_dir, f\"{img_id}.tif\")\n",
    "        \n",
    "        # Load Image\n",
    "        try:\n",
    "            with rasterio.open(img_path) as src:\n",
    "                image = src.read([1, 2, 3, 4]) \n",
    "                image = torch.from_numpy(image).float()\n",
    "                \n",
    "                if image.shape[1] != 224:\n",
    "                     image = torch.nn.functional.interpolate(\n",
    "                        image.unsqueeze(0), size=(224, 224), mode='bilinear', align_corners=False\n",
    "                    ).squeeze(0)\n",
    "        except Exception as e:\n",
    "            image = torch.zeros((4, 224, 224), dtype=torch.float32)\n",
    "\n",
    "        image = image / 255.0  \n",
    "        image = self.normalize(image)\n",
    "        \n",
    "        tab = torch.tensor(self.tab_data[idx], dtype=torch.float32)\n",
    "        \n",
    "        return image, tab, img_id\n",
    "\n",
    "# ==========================================\n",
    "# 3. MODEL ARCHITECTURE (Concatenation Style)\n",
    "# ==========================================\n",
    "class FusionModel(nn.Module):\n",
    "    def __init__(self, tab_input_dim):\n",
    "        super(FusionModel, self).__init__()\n",
    "        \n",
    "        # Backbone\n",
    "        self.cnn = models.resnet50(weights=None)\n",
    "        \n",
    "        # 4-Channel Adapter\n",
    "        original_weights = self.cnn.conv1.weight.data\n",
    "        new_conv1 = nn.Conv2d(4, 64, kernel_size=7, stride=2, padding=3, bias=False)\n",
    "        self.cnn.conv1 = new_conv1\n",
    "        self.cnn.fc = nn.Identity() \n",
    "\n",
    "        # Head\n",
    "        self.vis_compression = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(512, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "\n",
    "        self.tab_dim = tab_input_dim\n",
    "        self.head = nn.Linear(64 + self.tab_dim, 1)\n",
    "\n",
    "    def forward(self, img, tab):\n",
    "        vis_feat = self.cnn(img)              \n",
    "        vis_feat = self.vis_compression(vis_feat) \n",
    "        combined = torch.cat((vis_feat, tab), dim=1) \n",
    "        return self.head(combined).squeeze()\n",
    "\n",
    "# ==========================================\n",
    "# 4. MAIN INFERENCE LOOP\n",
    "# ==========================================\n",
    "def main():\n",
    "    print(\"--- 1. Loading and Merging Data ---\")\n",
    "    \n",
    "    test_df = pd.read_csv(TEST_TABULAR_PATH)\n",
    "    xgb_df = pd.read_csv(XGB_TEST_PATH)\n",
    "    \n",
    "    if 'price' in xgb_df.columns:\n",
    "        xgb_df = xgb_df.rename(columns={'price': 'xg_boost_price'})\n",
    "        \n",
    "    full_test_df = pd.merge(test_df, xgb_df[['id', 'xg_boost_price']], on='id', how='left')\n",
    "    \n",
    "    # Preprocess (Drops 'yr_built', 'yr_renovated' to match training dim)\n",
    "    full_test_df = preprocess_tabular_features(full_test_df)\n",
    "    \n",
    "    # Init Dataset\n",
    "    test_dataset = TestMultimodalDataset(full_test_df, IMG_DIR)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
    "    \n",
    "    print(f\"Features in Test: {len(test_dataset.features)} (Should correspond to model input)\")\n",
    "\n",
    "    print(\"--- 2. Loading Model ---\")\n",
    "    model = FusionModel(tab_input_dim=len(test_dataset.features))\n",
    "    \n",
    "    # Load Weights (Ignore missing keys logic helps if there are minor diffs, but dimensions must match)\n",
    "    state_dict = torch.load(MODEL_PATH, map_location=DEVICE)\n",
    "    model.load_state_dict(state_dict)\n",
    "    \n",
    "    model.to(DEVICE)\n",
    "    model.eval()\n",
    "    \n",
    "    print(\"--- 3. Running Inference ---\")\n",
    "    all_ids = []\n",
    "    all_log_residuals = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for imgs, tabs, ids in tqdm(test_loader, desc=\"Predicting\"):\n",
    "            imgs = imgs.to(DEVICE)\n",
    "            tabs = tabs.to(DEVICE)\n",
    "            \n",
    "            preds = model(imgs, tabs)\n",
    "            \n",
    "            all_log_residuals.extend(preds.cpu().numpy())\n",
    "            all_ids.extend(ids.numpy())\n",
    "            \n",
    "    print(\"--- 4. Fusing Scores & Saving ---\")\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "        'id': all_ids,\n",
    "        'pred_log_residual': all_log_residuals\n",
    "    })\n",
    "    \n",
    "    final_df = pd.merge(results_df, full_test_df[['id', 'xg_boost_price']], on='id', how='left')\n",
    "    \n",
    "    # Formula: Price = XGB * exp(residual)\n",
    "    final_df['predicted_alpha'] = np.exp(final_df['pred_log_residual'])\n",
    "    final_df['predicted_price'] = final_df['xg_boost_price'] * final_df['predicted_alpha']\n",
    "    \n",
    "    submission = final_df[['id', 'predicted_price']]\n",
    "    submission.to_csv(OUTPUT_PATH, index=False)\n",
    "    \n",
    "    print(f\"Success! Predictions saved to: {OUTPUT_PATH}\")\n",
    "    print(f\"Sample:\\n{submission.head()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
